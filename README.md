
## 3D Printed Object Dataset for Pose Estimation
This repository contains the necessary resources to use the dataset proposed on the work **A Study on the Impact of Domain Randomization for Monocular Deep 6DoF Pose Estimation**.
The dataset was designed to deal with pose estimation using 3D printed objects as a use case.
We provide the pose annotations in different sequences containing variations of lighting, movement speed and variation of the cameras used in the captures.

### Objects
The dataset consists of objects printed in 3d.: small size, rigid and generic shapes, textureless, and having uniform color. However, depending on the material used to print the object, the ambient lighting can have influence on the object color representation.

*Currently the dataset has a single object*

### Cameras
We currently provide calibration parameters and sequences for 2 different cameras:
* Apple Iphone X
* Samsung Galaxy S8

### Scenes
We record different sequences with specific characteristics. Currently, the dataset has the following scenes:
1. **Simple**: The camera circles around the object that is fixed at the center of a marker field. Movements are slow and controlled, indoor illumination is fixed;
2. **Motion**: Same as Simple but with faster camera motion, introducing motion blur and shaking;
3. **Illumination**: Same as Simple, but with changing illumination slightly
4. **Extreme**: Challenging illumination scenario with faster camera motion. All indoor lights turned off, the room completely dark, and the object being illuminated by a small, moving point light.

*We use the same environment to record the videos. In the future, we will vary the environment and include sequences with occlusion, cluttered background and others challenges*

### Randomization
Additionally, we provide domain randomized images rendered by our synthetic image generation tool.
The available images are the same ones used for the experiments carried out in the paper.

## Dataset Structure
In the main folder of the dataset you can find the directories described below

### CAD
Contains CAD models of objects used for recording (available in .obj and .ply)

### cameras
Contains the calibration parameters for the cameras used.
In the calibration directory, you can find the videos used for calibration and an xml containing the values obtained.
There are also specific directories available for each camera containing the camera matrix and distortion coefficients saved in a txt (for easier reading with python/numpy).

### videos
In this folder are included the original videos used to annotate the poses.

> videos/\[obj_name\]/\[camera_name\]/\[scene\].mp4

### data
Contains frames and annotations extracted from recorded videos.
The structure follows with the name of the object (CAD name), name of the camera (APPLE_IPHONE_X or SAMSUNG GALAXY_S8) and scenario of the video (SIMPLE, MOTION, ILLUMINATION or EXTREME).

> data/\[obj_name\]/\[camera_name\]/\[scene\]

Within each scenario you can find the folders:
* **binary_mask**: Contains the binary masks of the object of interest in the image for each frame.
* **corners**: Contains the annotated values ​​of the bounding box 3d of the object in the scene (including the centroid). The corners values ​​are normalized by the camera resolution, to use them it is necessary to multiply by the desired image resolution. The corners are ordered on the sequence:  `[(minX, minY, minZ), (minX, minY, maxZ), (minX, maxY, minZ), (minX, maxY, maxZ), (maxX, minY, minZ), (maxX, minY, maxZ), (maxX, maxY, minZ), (maxX, maxY, maxZ)]`
* **depth**: Similar to binary_mask, but containing grayscale values ​​to describe the depth.
* **frames**: Contains images extracted from recorded videos.
* **masked_frames**: Similar to binary_mask, but containing RGB information. Used in augmentation with the binary masks to insert the object in random backgrounds.
* **poses**: Contains the annotated pose values ​​noted for each frame. The files have the values ​​for rvec and tvec, in that order.

Each object also has a directory with the data generated by the domain randomization process, generated by our synthetic rendering tool.

> data/\[obj_name\]/UNITY

The dataset folder also contains a directory containing the background images to apply the augmentation.

> data/background/VOC2012/JPEGImages

### frames-to-ignore
Some frames do not contain the correct pose annotation, due to noise in the capture tool. To disregard this data, there are files that include annotations of which frames are noisy.
The directory contain similar structure of the data folder:

> frames-to-ignore/\[obj_name\]/\[camera_name\]/\[scene\]/\[ignore_file\].txt

### util
This folder contains some auxiliary scripts to demonstrate the application in random backgrounds, validate poses and points and mix real and synthetic information.

### Download data
You can download the resources through the links:
* [recorded videos](https://drive.google.com/uc?id=1CMnFhF_xsviXDJ4ix7eaHcTPNEVvfCAB&export=download)
* [annotated dataset](https://drive.google.com/uc?id=16jiJBC9DJEkexh_fjtrwfJJebj0w6krH&export=download)
* [camera calibration](https://drive.google.com/uc?id=1zteDJ43CEXDIcwk_V6og46hHlMIP-CVA&export=download)
* [background images](https://drive.google.com/uc?id=1uPphPGVIaHQQJVcYziE_0otFayl9P6Gt&export=download)

after downloading extract the data in the project folder

or you can run the script to download and extract all the data .: `./download.sh`

### Notes
We are planning for next updates the addition of more objects, cameras with different specifications, variations of scenarios, and new environment challenges.

We removed the augmented images with background variations, but you can generate them using the script contained in util, running: `python changeBackground_sample.py`.

## Citation
If you use this dataset, please cite the following
> @inproceedings{cunha20dr,  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TITLE = {{A Study on the Impact of Domain Randomization for Monocular Deep 6DoF Pose Estimation}}, 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AUTHOR = {da Cunha, Kelvin B and Brito, Caio and Valenca, Lucas and Simoes, Francisco and Teichrieb, Veronica},  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BOOKTITLE =  {2020 33st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;YEAR = {2020}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ORGANIZATION={IEEE}  
}

